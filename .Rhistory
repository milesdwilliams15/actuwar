res <- furrr::future_map_dfr(
1:(its * nrow(pdata)), function(i) {
out      <- as.data.frame(newdata)
out$sim  <- i
out$pred <- actuar::rinvburr(
nrow(pdata),
scale = param_fit(model, par = "mu", se = se),
shape1 = param_fit(model, par = "alpha", se = se),
shape2 = param_fit(model, par = "theta", se = se)
)
## return output
out
},
.options = furrr::furrr_options(seed = TRUE)
)
## return the simulated output
res
}
ibm_sim(
fit,
newdata = tibble(pop = range(wars$pop))
) -> test
ibm_sim(
fit,
newdata = tibble::tibble(pop = range(wars$pop))
) -> test
test
wars
#'
#' @param data A data object for the variable you want to plot.
#' @param x The variable for which you you want to plot Pr(X > x).
#' @param by An optional grouping variable. Should be a character or factor.
#' @param show_fit If `TRUE` the plot will include an inverse Burr fit for the data. Default is `FALSE`.
#'
#' @returns A ggplot object showing the relationship between a variable and its empirical Pr(X > x), both on a log-10 scale.
#'
#' @examples llplot(wars, fat, show_fit = T)
#' @export
llplot <- function(data, x, by, show_fit = FALSE) {
if(missing(data)) {
stop("A data object is missing. Did you forget to include a dataset?")
}
if(missing(by)) {
x <- dplyr::enquo(x)
data |>
dplyr::transmute(
by = 0,
x = !!x
) -> ndata
} else {
by <- dplyr::enquo(by)
x  <- dplyr::enquo(x)
data |>
dplyr::transmute(
by = !!by,
x = !!x,
) -> ndata
}
ndata |>
tidyr::drop_na() |>
dplyr::group_by(by) |>
dplyr::mutate(
p = rank(-x) / max(rank(-x))
) -> ndata
if(show_fit) {
ndata |>
dplyr::group_split(by) |>
purrr::map(~ {
fit <- ibm(x, data = .x, its = 1, verbose = F)
.x |>
dplyr::mutate(
fit = actuar::pinvburr(
q = x,
scale = exp(fit$summary$estimate[1]),
shape1 = exp(fit$summary$estimate[2]),
shape2 = exp(fit$summary$estimate[3]),
lower.tail = F
)
)
}) |>
dplyr::bind_rows() -> ndata
}
ggplot2::ggplot(ndata) +
ggplot2::aes(x = x, y = p, color = by) +
ggplot2::geom_point(
show.legend = !missing(by),
alpha = .4
) +
ggplot2::scale_x_log10() +
ggplot2::scale_y_log10() +
ggplot2::labs(
x = dplyr::enquo(x),
y = "Pr(X > x)"
) -> the_plot
if(show_fit) {
the_plot +
ggplot2::geom_line(
ggplot2::aes(y = fit),
show.legend = !missing(by),
linewidth = .75
) -> the_plot
}
the_plot
}
#'   \item{upper}{The upper bound of the bootstrapped confidence interval.}
#' }
#'
#' @examples
#' library(dplyr)
#' wars |>
#'   group_by(post1950) |>
#'   boot_b(fat, thresh = 1e06, ci = .84)
#'
#' @export
boot_p <- function(data, var, thresh, its = 1000, ci = 0.95) {
## return error if val is missing
if(missing(thresh)) {
stop("Option 'thresh' is missing. You should specify a threshold value for which to compute Pr(X > x).")
}
## get the observed Pr(X > x)
data |>
dplyr::mutate(
x = !!dplyr::enquo(var)
) -> data
data |>
dplyr::summarize(
estimate = mean(x > thresh)
) -> obs_out
## bootstrap the data and get Pr(X > x)
1:its |>
furrr::future_map_dfr(
~ data |>
dplyr::sample_n(nrow(data), T) |>
dplyr::summarize(
prob = mean(x > thresh),
.groups = "keep"
),
.options = furrr::furrr_options(seed = T)
) -> boot_out
## return a summary of bootstrapped Pr(X > x)
boot_out |>
dplyr::summarize(
lower = quantile(prob, 1 - (ci + (1 - ci) / 2)),
upper = quantile(prob, ci + (1 - ci) / 2),
) -> boot_out
if(nrow(obs_out) == 1) {
dplyr::bind_cols(obs_out, boot_out)
} else {
suppressMessages(dplyr::left_join(obs_out, boot_out))
}
}
library(dplyr)
wars |>
group_by(post1950) |>
boot_p(fat, thresh = 1e06, ci = .84)
rm(list = ls())
devtools::document()
```
data("wars") # use `wars` data object with {actuwar}
ibm(
outcome = fat,
mu = ~ log(pop) + maj + dem,
alpha = ~ log(pop) + maj + dem,
theta = ~ log(pop) + maj + dem,
data = wars
) -> model_fit
model_fit$summary
sample.int(10, 10, T)
sample.int(10, 10, T)
sample.int(10, 10, T)
sample.int(10, 10, T)
sample(1:10, 10, T)
sample(1:10, 10, T)
sample(1:10, 10, T)
sample(1:10, 10, T)
fit <- ibm(fat, ~ pop, ~ pop, ~ pop, wars, 200, F)
fit$boot_values
model_fit$boot_values
summary(wars$pop)
library(furrr)
cores <- availableCores() - 1
plan(multisession, workers = cores)
## estimate the model
ibm(
outcome = fat,
mu = ~ pop + maj + dem,
alpha = ~ pop + maj + dem,
theta = ~ pop + maj + dem,
data = wars
) -> model_fit
fit$convergence
model_fit$convergence
?optim
?`||`
#'   \item{model_matrix}{The combined model matrix used for estimation.}
#'   \item{logLik}{The maximized log-likelihood value.}
#'   \item{convergence}{Logical indicating whether optimization converged.}
#' }
#'
#' @examples
#' fit <- ibm(fat, ~ pre1950 + dem, ~ pre1950 + dem, ~ pre1950 + dem, wars)
#' fit$summary
#'
#' @export
ibm <- function(
outcome,
mu = ~ 1,
alpha = ~ 1,
theta = ~ 1,
data = NULL,
its = 2000,
verbose = TRUE
) {
## --------------------------
## Input checks
## --------------------------
if (!is.numeric(its) || its <= 0) {
stop("`its` must be a positive integer.")
}
if (!is.null(data)) {
y <- dplyr::pull(data, !!rlang::enquo(outcome))
} else {
y <- outcome
}
if (!is.numeric(y)) {
stop("Outcome must be numeric.")
}
if (anyNA(y)) {
stop("Missing values are not allowed.")
}
if (any(y <= 0)) {
stop("Outcome must be strictly positive for the inverse Burr distribution.")
}
## --------------------------
## Model matrices
## --------------------------
if (is.null(data) &&
(!identical(mu, ~1) ||
!identical(alpha, ~1) ||
!identical(theta, ~1))) {
stop("If formulas include covariates, `data` must be supplied.")
}
x1 <- stats::model.matrix(mu, data)
x2 <- stats::model.matrix(alpha, data)
x3 <- stats::model.matrix(theta, data)
model_matrix <- cbind(x1, x2, x3)
p1 <- ncol(x1)
p2 <- ncol(x2)
p3 <- ncol(x3)
p_total <- p1 + p2 + p3
## --------------------------
## Likelihood
## --------------------------
inbur_lik <- function(pars, x1, x2, x3, y) {
b1 <- pars[1:p1]
b2 <- pars[(p1 + 1):(p1 + p2)]
b3 <- pars[(p1 + p2 + 1):(p_total)]
mu_val    <- exp(x1 %*% b1)
alpha_val <- exp(x2 %*% b2)
theta_val <- exp(x3 %*% b3)
dens <- actuar::dinvburr(
y,
shape1 = alpha_val,
shape2 = theta_val,
scale  = mu_val
)
if (any(dens <= 0) || any(!is.finite(dens))) {
return(Inf)
}
-sum(log(dens))
}
## --------------------------
## Estimation
## --------------------------
if (verbose) message("Fitting model...")
opt_out <- stats::optim(
par = rep(0, p_total),
fn  = inbur_lik,
x1 = x1,
x2 = x2,
x3 = x3,
y  = y,
hessian = FALSE
)
converged <- opt_out$convergence != 0
if (!converged) {
warning("Optimization may not have converged.")
}
## --------------------------
## Bootstrap
## --------------------------
if (verbose) message("Bootstrapping ", its, " iterations...")
boot_list <- furrr::future_map(
seq_len(its),
function(i) {
idx <- sample.int(length(y), length(y), replace = TRUE)
res <- try(
stats::optim(
par = opt_out$par,
fn  = inbur_lik,
x1 = x1[idx, , drop = FALSE],
x2 = x2[idx, , drop = FALSE],
x3 = x3[idx, , drop = FALSE],
y  = y[idx],
hessian = FALSE
),
silent = TRUE
)
if (inherits(res, "try-error")) {
return(rep(NA_real_, p_total))
}
res$par
},
.options = furrr::furrr_options(seed = TRUE)
)
boot_mat <- do.call(rbind, boot_list)
boot_se <- apply(boot_mat, 2, stats::sd, na.rm = TRUE)
## --------------------------
## Summary construction
## --------------------------
est <- opt_out$par
z   <- est / boot_se
p   <- 2 * stats::pnorm(-abs(z))
param_labels <- c(
rep("mu", p1),
rep("alpha", p2),
rep("theta", p3)
)
term_labels <- c(
colnames(x1),
colnames(x2),
colnames(x3)
)
summary_tbl <- tibble::tibble(
param = param_labels,
term = term_labels,
estimate = est,
std.error = boot_se,
statistic = z,
p.value = round(p, 3)
)
boot_values <- tibble::tibble(
iteration = rep(seq_len(its), each = p_total),
param = rep(param_labels, times = its),
term = rep(term_labels, times = its),
estimate = as.vector(t(boot_mat))
)
if (verbose) message("Done.")
## --------------------------
## Return
## --------------------------
list(
summary = summary_tbl,
boot_values = boot_values,
model_matrix = model_matrix,
logLik = -opt_out$value,
convergence = converged
)
}
ibm(
outcome = fat,
mu = ~ pop + maj + dem,
alpha = ~ pop + maj + dem,
theta = ~ pop + maj + dem,
data = wars
) -> model_fit
model_fit$boot_values
model_fit$summary
model_fit$summary |> round(3)
model_fit$summary |> mutate(across(3:6, ~ round(.x, 3)))
model_fit$summary
model_fit$summary |> cat()
model_fit$summary |> as.data.fram()
model_fit$summary |> as.data.frame()
model_fit$summary |> mutate(across(3:6, ~ round(.x, 2)))
ibm_sim(
model_fit,
newdata = data.frame(
pop = mean(wars$pop),
maj = mean(wars$maj),
dem = c(-5, 0, 5)
)
) -> sim_data
llplot(sim_data, pred, by = dem) +
scale_color_gradient2(
low = "red",
mid = "gray",
high = "blue",
guide = "legend",
breaks = c(-5, 0, 5)
) +
labs(
color = "Avg. Polity 2"
) +
theme(
legend.position = c(.2, .25),
legend.title = element_text(size = 8)
)
ibm_sim(
model_fit,
newdata = data.frame(
pop = mean(wars$pop),
maj = mean(wars$maj),
dem = c(-5, 0, 5)
),
se = T
) -> sim_data
#' @param its The number of random draws. The default is 1,000.
#' @param newdata An optional data frame with new covariate values to use for simulated values.
#' @param se Specify whether coefficient standard errors should be factored into the simulation. Default is `FALSE`.
#' @returns A data frame, either the original model matrix or the new data object supplied along with simulated predictions in a new column called `pred`. The returned data frame will have as many rows as simulation iterations times the number of unique covariate value combinations provided.
#'
#' @examples
#' fit   <- ibm(fat, ~ post1950 + dem, ~ post1950 + dem, ~ post1950 + dem, wars)
#' preds <- ibm_sim(fit, newdata = data.frame(post1950 == "post-1950", dem = .5))
#'
#' @export
ibm_sim <- function(model, its = 1000, newdata = NULL, se = FALSE) {
## specify the data for simulations
newdata <- if(is.null(newdata)) as.data.frame(model$model_matrix) else as.data.frame(newdata)
dnames  <- colnames(model$model_matrix)
ndata   <- matrix(1, nrow(newdata), length(dnames))
colnames(ndata) <- dnames
for(i in 1:length(dnames)) {
if(dnames[i] %in% colnames(newdata)) {
ndata[, i] <- newdata[, colnames(newdata) == dnames[i]]
}
}
pdata <- ndata
## make a function to calculate conditional fitted parameters given data
param_fit <- function(model, data = pdata, par, se) {
npars <- 1:nrow(model$summary)
names(npars) <- model$summary$param
X <- data[, npars[names(npars) == par]]
if(se) {
s_its <- sample(unique(model$boot_values$iteration), 1)
coefs <- model$boot_values[model$boot_values$iteration == s_its &
model$boot_values$param == par, ]$estimate
} else {
coefs <- model$summary[model$summary$param == par, ]$estimate
}
exp(X %*% coefs)
}
## iteratively simulate new outcomes
res <- furrr::future_map_dfr(
1:(its * nrow(pdata)), function(i) {
out      <- as.data.frame(newdata)
out$sim  <- i
out$pred <- actuar::rinvburr(
nrow(pdata),
scale = param_fit(model, par = "mu", se = se),
shape1 = param_fit(model, par = "alpha", se = se),
shape2 = param_fit(model, par = "theta", se = se)
)
## return output
out
},
.options = furrr::furrr_options(seed = TRUE)
)
## return the simulated output
res
}
ibm_sim(
model_fit,
newdata = data.frame(
pop = mean(wars$pop),
maj = mean(wars$maj),
dem = c(-5, 0, 5)
),
se = T
) -> sim_data
llplot(sim_data, pred, by = dem) +
scale_color_gradient2(
low = "red",
mid = "gray",
high = "blue",
guide = "legend",
breaks = c(-5, 0, 5)
) +
labs(
color = "Avg. Polity 2"
) +
theme(
legend.position = c(.2, .25),
legend.title = element_text(size = 8)
)
wars |>
group_by(post1950) |>
boot_p(fat, thresh = 1e06, ci = 0.834) |>
ggplot() +
aes(post1950, estimate, ymin = lower, ymax = upper) +
geom_pointrange()
sim_data |>
group_by(dem) |>
boot_p(pred, thresh = 16e06, ci = 0.834) |>
ggplot() +
aes(as.factor(dem), estimate, ymin = boot_lower, ymax = boot_upper) +
geom_pointrange()
sim_data |>
group_by(dem) |>
boot_p(pred, thresh = 16e06, ci = 0.834) |>
ggplot() +
aes(as.factor(dem), estimate, ymin = lower, ymax = upper) +
geom_pointrange()
devtools::document()
rm(list = ls())
devtools::document()
?ibm
?ibm_sim
?llplot
?boot_p
devtools::check()
